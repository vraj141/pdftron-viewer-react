{"ast":null,"code":"var fs = require(\"fs\");\n\nvar zlib = require(\"zlib\");\n\nvar fd_slicer = require(\"fd-slicer\");\n\nvar crc32 = require(\"buffer-crc32\");\n\nvar util = require(\"util\");\n\nvar EventEmitter = require(\"events\").EventEmitter;\n\nvar Transform = require(\"stream\").Transform;\n\nvar PassThrough = require(\"stream\").PassThrough;\n\nvar Writable = require(\"stream\").Writable;\n\nexports.open = open;\nexports.fromFd = fromFd;\nexports.fromBuffer = fromBuffer;\nexports.fromRandomAccessReader = fromRandomAccessReader;\nexports.dosDateTimeToDate = dosDateTimeToDate;\nexports.validateFileName = validateFileName;\nexports.ZipFile = ZipFile;\nexports.Entry = Entry;\nexports.RandomAccessReader = RandomAccessReader;\n\nfunction open(path, options, callback) {\n  if (typeof options === \"function\") {\n    callback = options;\n    options = null;\n  }\n\n  if (options == null) options = {};\n  if (options.autoClose == null) options.autoClose = true;\n  if (options.lazyEntries == null) options.lazyEntries = false;\n  if (options.decodeStrings == null) options.decodeStrings = true;\n  if (options.validateEntrySizes == null) options.validateEntrySizes = true;\n  if (options.strictFileNames == null) options.strictFileNames = false;\n  if (callback == null) callback = defaultCallback;\n  fs.open(path, \"r\", function (err, fd) {\n    if (err) return callback(err);\n    fromFd(fd, options, function (err, zipfile) {\n      if (err) fs.close(fd, defaultCallback);\n      callback(err, zipfile);\n    });\n  });\n}\n\nfunction fromFd(fd, options, callback) {\n  if (typeof options === \"function\") {\n    callback = options;\n    options = null;\n  }\n\n  if (options == null) options = {};\n  if (options.autoClose == null) options.autoClose = false;\n  if (options.lazyEntries == null) options.lazyEntries = false;\n  if (options.decodeStrings == null) options.decodeStrings = true;\n  if (options.validateEntrySizes == null) options.validateEntrySizes = true;\n  if (options.strictFileNames == null) options.strictFileNames = false;\n  if (callback == null) callback = defaultCallback;\n  fs.fstat(fd, function (err, stats) {\n    if (err) return callback(err);\n    var reader = fd_slicer.createFromFd(fd, {\n      autoClose: true\n    });\n    fromRandomAccessReader(reader, stats.size, options, callback);\n  });\n}\n\nfunction fromBuffer(buffer, options, callback) {\n  if (typeof options === \"function\") {\n    callback = options;\n    options = null;\n  }\n\n  if (options == null) options = {};\n  options.autoClose = false;\n  if (options.lazyEntries == null) options.lazyEntries = false;\n  if (options.decodeStrings == null) options.decodeStrings = true;\n  if (options.validateEntrySizes == null) options.validateEntrySizes = true;\n  if (options.strictFileNames == null) options.strictFileNames = false; // limit the max chunk size. see https://github.com/thejoshwolfe/yauzl/issues/87\n\n  var reader = fd_slicer.createFromBuffer(buffer, {\n    maxChunkSize: 0x10000\n  });\n  fromRandomAccessReader(reader, buffer.length, options, callback);\n}\n\nfunction fromRandomAccessReader(reader, totalSize, options, callback) {\n  if (typeof options === \"function\") {\n    callback = options;\n    options = null;\n  }\n\n  if (options == null) options = {};\n  if (options.autoClose == null) options.autoClose = true;\n  if (options.lazyEntries == null) options.lazyEntries = false;\n  if (options.decodeStrings == null) options.decodeStrings = true;\n  var decodeStrings = !!options.decodeStrings;\n  if (options.validateEntrySizes == null) options.validateEntrySizes = true;\n  if (options.strictFileNames == null) options.strictFileNames = false;\n  if (callback == null) callback = defaultCallback;\n  if (typeof totalSize !== \"number\") throw new Error(\"expected totalSize parameter to be a number\");\n\n  if (totalSize > Number.MAX_SAFE_INTEGER) {\n    throw new Error(\"zip file too large. only file sizes up to 2^52 are supported due to JavaScript's Number type being an IEEE 754 double.\");\n  } // the matching unref() call is in zipfile.close()\n\n\n  reader.ref(); // eocdr means End of Central Directory Record.\n  // search backwards for the eocdr signature.\n  // the last field of the eocdr is a variable-length comment.\n  // the comment size is encoded in a 2-byte field in the eocdr, which we can't find without trudging backwards through the comment to find it.\n  // as a consequence of this design decision, it's possible to have ambiguous zip file metadata if a coherent eocdr was in the comment.\n  // we search backwards for a eocdr signature, and hope that whoever made the zip file was smart enough to forbid the eocdr signature in the comment.\n\n  var eocdrWithoutCommentSize = 22;\n  var maxCommentSize = 0xffff; // 2-byte size\n\n  var bufferSize = Math.min(eocdrWithoutCommentSize + maxCommentSize, totalSize);\n  var buffer = newBuffer(bufferSize);\n  var bufferReadStart = totalSize - buffer.length;\n  readAndAssertNoEof(reader, buffer, 0, bufferSize, bufferReadStart, function (err) {\n    if (err) return callback(err);\n\n    for (var i = bufferSize - eocdrWithoutCommentSize; i >= 0; i -= 1) {\n      if (buffer.readUInt32LE(i) !== 0x06054b50) continue; // found eocdr\n\n      var eocdrBuffer = buffer.slice(i); // 0 - End of central directory signature = 0x06054b50\n      // 4 - Number of this disk\n\n      var diskNumber = eocdrBuffer.readUInt16LE(4);\n\n      if (diskNumber !== 0) {\n        return callback(new Error(\"multi-disk zip files are not supported: found disk number: \" + diskNumber));\n      } // 6 - Disk where central directory starts\n      // 8 - Number of central directory records on this disk\n      // 10 - Total number of central directory records\n\n\n      var entryCount = eocdrBuffer.readUInt16LE(10); // 12 - Size of central directory (bytes)\n      // 16 - Offset of start of central directory, relative to start of archive\n\n      var centralDirectoryOffset = eocdrBuffer.readUInt32LE(16); // 20 - Comment length\n\n      var commentLength = eocdrBuffer.readUInt16LE(20);\n      var expectedCommentLength = eocdrBuffer.length - eocdrWithoutCommentSize;\n\n      if (commentLength !== expectedCommentLength) {\n        return callback(new Error(\"invalid comment length. expected: \" + expectedCommentLength + \". found: \" + commentLength));\n      } // 22 - Comment\n      // the encoding is always cp437.\n\n\n      var comment = decodeStrings ? decodeBuffer(eocdrBuffer, 22, eocdrBuffer.length, false) : eocdrBuffer.slice(22);\n\n      if (!(entryCount === 0xffff || centralDirectoryOffset === 0xffffffff)) {\n        return callback(null, new ZipFile(reader, centralDirectoryOffset, totalSize, entryCount, comment, options.autoClose, options.lazyEntries, decodeStrings, options.validateEntrySizes, options.strictFileNames));\n      } // ZIP64 format\n      // ZIP64 Zip64 end of central directory locator\n\n\n      var zip64EocdlBuffer = newBuffer(20);\n      var zip64EocdlOffset = bufferReadStart + i - zip64EocdlBuffer.length;\n      readAndAssertNoEof(reader, zip64EocdlBuffer, 0, zip64EocdlBuffer.length, zip64EocdlOffset, function (err) {\n        if (err) return callback(err); // 0 - zip64 end of central dir locator signature = 0x07064b50\n\n        if (zip64EocdlBuffer.readUInt32LE(0) !== 0x07064b50) {\n          return callback(new Error(\"invalid zip64 end of central directory locator signature\"));\n        } // 4 - number of the disk with the start of the zip64 end of central directory\n        // 8 - relative offset of the zip64 end of central directory record\n\n\n        var zip64EocdrOffset = readUInt64LE(zip64EocdlBuffer, 8); // 16 - total number of disks\n        // ZIP64 end of central directory record\n\n        var zip64EocdrBuffer = newBuffer(56);\n        readAndAssertNoEof(reader, zip64EocdrBuffer, 0, zip64EocdrBuffer.length, zip64EocdrOffset, function (err) {\n          if (err) return callback(err); // 0 - zip64 end of central dir signature                           4 bytes  (0x06064b50)\n\n          if (zip64EocdrBuffer.readUInt32LE(0) !== 0x06064b50) {\n            return callback(new Error(\"invalid zip64 end of central directory record signature\"));\n          } // 4 - size of zip64 end of central directory record                8 bytes\n          // 12 - version made by                                             2 bytes\n          // 14 - version needed to extract                                   2 bytes\n          // 16 - number of this disk                                         4 bytes\n          // 20 - number of the disk with the start of the central directory  4 bytes\n          // 24 - total number of entries in the central directory on this disk         8 bytes\n          // 32 - total number of entries in the central directory            8 bytes\n\n\n          entryCount = readUInt64LE(zip64EocdrBuffer, 32); // 40 - size of the central directory                               8 bytes\n          // 48 - offset of start of central directory with respect to the starting disk number     8 bytes\n\n          centralDirectoryOffset = readUInt64LE(zip64EocdrBuffer, 48); // 56 - zip64 extensible data sector                                (variable size)\n\n          return callback(null, new ZipFile(reader, centralDirectoryOffset, totalSize, entryCount, comment, options.autoClose, options.lazyEntries, decodeStrings, options.validateEntrySizes, options.strictFileNames));\n        });\n      });\n      return;\n    }\n\n    callback(new Error(\"end of central directory record signature not found\"));\n  });\n}\n\nutil.inherits(ZipFile, EventEmitter);\n\nfunction ZipFile(reader, centralDirectoryOffset, fileSize, entryCount, comment, autoClose, lazyEntries, decodeStrings, validateEntrySizes, strictFileNames) {\n  var self = this;\n  EventEmitter.call(self);\n  self.reader = reader; // forward close events\n\n  self.reader.on(\"error\", function (err) {\n    // error closing the fd\n    emitError(self, err);\n  });\n  self.reader.once(\"close\", function () {\n    self.emit(\"close\");\n  });\n  self.readEntryCursor = centralDirectoryOffset;\n  self.fileSize = fileSize;\n  self.entryCount = entryCount;\n  self.comment = comment;\n  self.entriesRead = 0;\n  self.autoClose = !!autoClose;\n  self.lazyEntries = !!lazyEntries;\n  self.decodeStrings = !!decodeStrings;\n  self.validateEntrySizes = !!validateEntrySizes;\n  self.strictFileNames = !!strictFileNames;\n  self.isOpen = true;\n  self.emittedError = false;\n  if (!self.lazyEntries) self._readEntry();\n}\n\nZipFile.prototype.close = function () {\n  if (!this.isOpen) return;\n  this.isOpen = false;\n  this.reader.unref();\n};\n\nfunction emitErrorAndAutoClose(self, err) {\n  if (self.autoClose) self.close();\n  emitError(self, err);\n}\n\nfunction emitError(self, err) {\n  if (self.emittedError) return;\n  self.emittedError = true;\n  self.emit(\"error\", err);\n}\n\nZipFile.prototype.readEntry = function () {\n  if (!this.lazyEntries) throw new Error(\"readEntry() called without lazyEntries:true\");\n\n  this._readEntry();\n};\n\nZipFile.prototype._readEntry = function () {\n  var self = this;\n\n  if (self.entryCount === self.entriesRead) {\n    // done with metadata\n    setImmediate(function () {\n      if (self.autoClose) self.close();\n      if (self.emittedError) return;\n      self.emit(\"end\");\n    });\n    return;\n  }\n\n  if (self.emittedError) return;\n  var buffer = newBuffer(46);\n  readAndAssertNoEof(self.reader, buffer, 0, buffer.length, self.readEntryCursor, function (err) {\n    if (err) return emitErrorAndAutoClose(self, err);\n    if (self.emittedError) return;\n    var entry = new Entry(); // 0 - Central directory file header signature\n\n    var signature = buffer.readUInt32LE(0);\n    if (signature !== 0x02014b50) return emitErrorAndAutoClose(self, new Error(\"invalid central directory file header signature: 0x\" + signature.toString(16))); // 4 - Version made by\n\n    entry.versionMadeBy = buffer.readUInt16LE(4); // 6 - Version needed to extract (minimum)\n\n    entry.versionNeededToExtract = buffer.readUInt16LE(6); // 8 - General purpose bit flag\n\n    entry.generalPurposeBitFlag = buffer.readUInt16LE(8); // 10 - Compression method\n\n    entry.compressionMethod = buffer.readUInt16LE(10); // 12 - File last modification time\n\n    entry.lastModFileTime = buffer.readUInt16LE(12); // 14 - File last modification date\n\n    entry.lastModFileDate = buffer.readUInt16LE(14); // 16 - CRC-32\n\n    entry.crc32 = buffer.readUInt32LE(16); // 20 - Compressed size\n\n    entry.compressedSize = buffer.readUInt32LE(20); // 24 - Uncompressed size\n\n    entry.uncompressedSize = buffer.readUInt32LE(24); // 28 - File name length (n)\n\n    entry.fileNameLength = buffer.readUInt16LE(28); // 30 - Extra field length (m)\n\n    entry.extraFieldLength = buffer.readUInt16LE(30); // 32 - File comment length (k)\n\n    entry.fileCommentLength = buffer.readUInt16LE(32); // 34 - Disk number where file starts\n    // 36 - Internal file attributes\n\n    entry.internalFileAttributes = buffer.readUInt16LE(36); // 38 - External file attributes\n\n    entry.externalFileAttributes = buffer.readUInt32LE(38); // 42 - Relative offset of local file header\n\n    entry.relativeOffsetOfLocalHeader = buffer.readUInt32LE(42);\n    if (entry.generalPurposeBitFlag & 0x40) return emitErrorAndAutoClose(self, new Error(\"strong encryption is not supported\"));\n    self.readEntryCursor += 46;\n    buffer = newBuffer(entry.fileNameLength + entry.extraFieldLength + entry.fileCommentLength);\n    readAndAssertNoEof(self.reader, buffer, 0, buffer.length, self.readEntryCursor, function (err) {\n      if (err) return emitErrorAndAutoClose(self, err);\n      if (self.emittedError) return; // 46 - File name\n\n      var isUtf8 = (entry.generalPurposeBitFlag & 0x800) !== 0;\n      entry.fileName = self.decodeStrings ? decodeBuffer(buffer, 0, entry.fileNameLength, isUtf8) : buffer.slice(0, entry.fileNameLength); // 46+n - Extra field\n\n      var fileCommentStart = entry.fileNameLength + entry.extraFieldLength;\n      var extraFieldBuffer = buffer.slice(entry.fileNameLength, fileCommentStart);\n      entry.extraFields = [];\n      var i = 0;\n\n      while (i < extraFieldBuffer.length - 3) {\n        var headerId = extraFieldBuffer.readUInt16LE(i + 0);\n        var dataSize = extraFieldBuffer.readUInt16LE(i + 2);\n        var dataStart = i + 4;\n        var dataEnd = dataStart + dataSize;\n        if (dataEnd > extraFieldBuffer.length) return emitErrorAndAutoClose(self, new Error(\"extra field length exceeds extra field buffer size\"));\n        var dataBuffer = newBuffer(dataSize);\n        extraFieldBuffer.copy(dataBuffer, 0, dataStart, dataEnd);\n        entry.extraFields.push({\n          id: headerId,\n          data: dataBuffer\n        });\n        i = dataEnd;\n      } // 46+n+m - File comment\n\n\n      entry.fileComment = self.decodeStrings ? decodeBuffer(buffer, fileCommentStart, fileCommentStart + entry.fileCommentLength, isUtf8) : buffer.slice(fileCommentStart, fileCommentStart + entry.fileCommentLength); // compatibility hack for https://github.com/thejoshwolfe/yauzl/issues/47\n\n      entry.comment = entry.fileComment;\n      self.readEntryCursor += buffer.length;\n      self.entriesRead += 1;\n\n      if (entry.uncompressedSize === 0xffffffff || entry.compressedSize === 0xffffffff || entry.relativeOffsetOfLocalHeader === 0xffffffff) {\n        // ZIP64 format\n        // find the Zip64 Extended Information Extra Field\n        var zip64EiefBuffer = null;\n\n        for (var i = 0; i < entry.extraFields.length; i++) {\n          var extraField = entry.extraFields[i];\n\n          if (extraField.id === 0x0001) {\n            zip64EiefBuffer = extraField.data;\n            break;\n          }\n        }\n\n        if (zip64EiefBuffer == null) {\n          return emitErrorAndAutoClose(self, new Error(\"expected zip64 extended information extra field\"));\n        }\n\n        var index = 0; // 0 - Original Size          8 bytes\n\n        if (entry.uncompressedSize === 0xffffffff) {\n          if (index + 8 > zip64EiefBuffer.length) {\n            return emitErrorAndAutoClose(self, new Error(\"zip64 extended information extra field does not include uncompressed size\"));\n          }\n\n          entry.uncompressedSize = readUInt64LE(zip64EiefBuffer, index);\n          index += 8;\n        } // 8 - Compressed Size        8 bytes\n\n\n        if (entry.compressedSize === 0xffffffff) {\n          if (index + 8 > zip64EiefBuffer.length) {\n            return emitErrorAndAutoClose(self, new Error(\"zip64 extended information extra field does not include compressed size\"));\n          }\n\n          entry.compressedSize = readUInt64LE(zip64EiefBuffer, index);\n          index += 8;\n        } // 16 - Relative Header Offset 8 bytes\n\n\n        if (entry.relativeOffsetOfLocalHeader === 0xffffffff) {\n          if (index + 8 > zip64EiefBuffer.length) {\n            return emitErrorAndAutoClose(self, new Error(\"zip64 extended information extra field does not include relative header offset\"));\n          }\n\n          entry.relativeOffsetOfLocalHeader = readUInt64LE(zip64EiefBuffer, index);\n          index += 8;\n        } // 24 - Disk Start Number      4 bytes\n\n      } // check for Info-ZIP Unicode Path Extra Field (0x7075)\n      // see https://github.com/thejoshwolfe/yauzl/issues/33\n\n\n      if (self.decodeStrings) {\n        for (var i = 0; i < entry.extraFields.length; i++) {\n          var extraField = entry.extraFields[i];\n\n          if (extraField.id === 0x7075) {\n            if (extraField.data.length < 6) {\n              // too short to be meaningful\n              continue;\n            } // Version       1 byte      version of this extra field, currently 1\n\n\n            if (extraField.data.readUInt8(0) !== 1) {\n              // > Changes may not be backward compatible so this extra\n              // > field should not be used if the version is not recognized.\n              continue;\n            } // NameCRC32     4 bytes     File Name Field CRC32 Checksum\n\n\n            var oldNameCrc32 = extraField.data.readUInt32LE(1);\n\n            if (crc32.unsigned(buffer.slice(0, entry.fileNameLength)) !== oldNameCrc32) {\n              // > If the CRC check fails, this UTF-8 Path Extra Field should be\n              // > ignored and the File Name field in the header should be used instead.\n              continue;\n            } // UnicodeName   Variable    UTF-8 version of the entry File Name\n\n\n            entry.fileName = decodeBuffer(extraField.data, 5, extraField.data.length, true);\n            break;\n          }\n        }\n      } // validate file size\n\n\n      if (self.validateEntrySizes && entry.compressionMethod === 0) {\n        var expectedCompressedSize = entry.uncompressedSize;\n\n        if (entry.isEncrypted()) {\n          // traditional encryption prefixes the file data with a header\n          expectedCompressedSize += 12;\n        }\n\n        if (entry.compressedSize !== expectedCompressedSize) {\n          var msg = \"compressed/uncompressed size mismatch for stored file: \" + entry.compressedSize + \" != \" + entry.uncompressedSize;\n          return emitErrorAndAutoClose(self, new Error(msg));\n        }\n      }\n\n      if (self.decodeStrings) {\n        if (!self.strictFileNames) {\n          // allow backslash\n          entry.fileName = entry.fileName.replace(/\\\\/g, \"/\");\n        }\n\n        var errorMessage = validateFileName(entry.fileName, self.validateFileNameOptions);\n        if (errorMessage != null) return emitErrorAndAutoClose(self, new Error(errorMessage));\n      }\n\n      self.emit(\"entry\", entry);\n      if (!self.lazyEntries) self._readEntry();\n    });\n  });\n};\n\nZipFile.prototype.openReadStream = function (entry, options, callback) {\n  var self = this; // parameter validation\n\n  var relativeStart = 0;\n  var relativeEnd = entry.compressedSize;\n\n  if (callback == null) {\n    callback = options;\n    options = {};\n  } else {\n    // validate options that the caller has no excuse to get wrong\n    if (options.decrypt != null) {\n      if (!entry.isEncrypted()) {\n        throw new Error(\"options.decrypt can only be specified for encrypted entries\");\n      }\n\n      if (options.decrypt !== false) throw new Error(\"invalid options.decrypt value: \" + options.decrypt);\n\n      if (entry.isCompressed()) {\n        if (options.decompress !== false) throw new Error(\"entry is encrypted and compressed, and options.decompress !== false\");\n      }\n    }\n\n    if (options.decompress != null) {\n      if (!entry.isCompressed()) {\n        throw new Error(\"options.decompress can only be specified for compressed entries\");\n      }\n\n      if (!(options.decompress === false || options.decompress === true)) {\n        throw new Error(\"invalid options.decompress value: \" + options.decompress);\n      }\n    }\n\n    if (options.start != null || options.end != null) {\n      if (entry.isCompressed() && options.decompress !== false) {\n        throw new Error(\"start/end range not allowed for compressed entry without options.decompress === false\");\n      }\n\n      if (entry.isEncrypted() && options.decrypt !== false) {\n        throw new Error(\"start/end range not allowed for encrypted entry without options.decrypt === false\");\n      }\n    }\n\n    if (options.start != null) {\n      relativeStart = options.start;\n      if (relativeStart < 0) throw new Error(\"options.start < 0\");\n      if (relativeStart > entry.compressedSize) throw new Error(\"options.start > entry.compressedSize\");\n    }\n\n    if (options.end != null) {\n      relativeEnd = options.end;\n      if (relativeEnd < 0) throw new Error(\"options.end < 0\");\n      if (relativeEnd > entry.compressedSize) throw new Error(\"options.end > entry.compressedSize\");\n      if (relativeEnd < relativeStart) throw new Error(\"options.end < options.start\");\n    }\n  } // any further errors can either be caused by the zipfile,\n  // or were introduced in a minor version of yauzl,\n  // so should be passed to the client rather than thrown.\n\n\n  if (!self.isOpen) return callback(new Error(\"closed\"));\n\n  if (entry.isEncrypted()) {\n    if (options.decrypt !== false) return callback(new Error(\"entry is encrypted, and options.decrypt !== false\"));\n  } // make sure we don't lose the fd before we open the actual read stream\n\n\n  self.reader.ref();\n  var buffer = newBuffer(30);\n  readAndAssertNoEof(self.reader, buffer, 0, buffer.length, entry.relativeOffsetOfLocalHeader, function (err) {\n    try {\n      if (err) return callback(err); // 0 - Local file header signature = 0x04034b50\n\n      var signature = buffer.readUInt32LE(0);\n\n      if (signature !== 0x04034b50) {\n        return callback(new Error(\"invalid local file header signature: 0x\" + signature.toString(16)));\n      } // all this should be redundant\n      // 4 - Version needed to extract (minimum)\n      // 6 - General purpose bit flag\n      // 8 - Compression method\n      // 10 - File last modification time\n      // 12 - File last modification date\n      // 14 - CRC-32\n      // 18 - Compressed size\n      // 22 - Uncompressed size\n      // 26 - File name length (n)\n\n\n      var fileNameLength = buffer.readUInt16LE(26); // 28 - Extra field length (m)\n\n      var extraFieldLength = buffer.readUInt16LE(28); // 30 - File name\n      // 30+n - Extra field\n\n      var localFileHeaderEnd = entry.relativeOffsetOfLocalHeader + buffer.length + fileNameLength + extraFieldLength;\n      var decompress;\n\n      if (entry.compressionMethod === 0) {\n        // 0 - The file is stored (no compression)\n        decompress = false;\n      } else if (entry.compressionMethod === 8) {\n        // 8 - The file is Deflated\n        decompress = options.decompress != null ? options.decompress : true;\n      } else {\n        return callback(new Error(\"unsupported compression method: \" + entry.compressionMethod));\n      }\n\n      var fileDataStart = localFileHeaderEnd;\n      var fileDataEnd = fileDataStart + entry.compressedSize;\n\n      if (entry.compressedSize !== 0) {\n        // bounds check now, because the read streams will probably not complain loud enough.\n        // since we're dealing with an unsigned offset plus an unsigned size,\n        // we only have 1 thing to check for.\n        if (fileDataEnd > self.fileSize) {\n          return callback(new Error(\"file data overflows file bounds: \" + fileDataStart + \" + \" + entry.compressedSize + \" > \" + self.fileSize));\n        }\n      }\n\n      var readStream = self.reader.createReadStream({\n        start: fileDataStart + relativeStart,\n        end: fileDataStart + relativeEnd\n      });\n      var endpointStream = readStream;\n\n      if (decompress) {\n        var destroyed = false;\n        var inflateFilter = zlib.createInflateRaw();\n        readStream.on(\"error\", function (err) {\n          // setImmediate here because errors can be emitted during the first call to pipe()\n          setImmediate(function () {\n            if (!destroyed) inflateFilter.emit(\"error\", err);\n          });\n        });\n        readStream.pipe(inflateFilter);\n\n        if (self.validateEntrySizes) {\n          endpointStream = new AssertByteCountStream(entry.uncompressedSize);\n          inflateFilter.on(\"error\", function (err) {\n            // forward zlib errors to the client-visible stream\n            setImmediate(function () {\n              if (!destroyed) endpointStream.emit(\"error\", err);\n            });\n          });\n          inflateFilter.pipe(endpointStream);\n        } else {\n          // the zlib filter is the client-visible stream\n          endpointStream = inflateFilter;\n        } // this is part of yauzl's API, so implement this function on the client-visible stream\n\n\n        endpointStream.destroy = function () {\n          destroyed = true;\n          if (inflateFilter !== endpointStream) inflateFilter.unpipe(endpointStream);\n          readStream.unpipe(inflateFilter); // TODO: the inflateFilter may cause a memory leak. see Issue #27.\n\n          readStream.destroy();\n        };\n      }\n\n      callback(null, endpointStream);\n    } finally {\n      self.reader.unref();\n    }\n  });\n};\n\nfunction Entry() {}\n\nEntry.prototype.getLastModDate = function () {\n  return dosDateTimeToDate(this.lastModFileDate, this.lastModFileTime);\n};\n\nEntry.prototype.isEncrypted = function () {\n  return (this.generalPurposeBitFlag & 0x1) !== 0;\n};\n\nEntry.prototype.isCompressed = function () {\n  return this.compressionMethod === 8;\n};\n\nfunction dosDateTimeToDate(date, time) {\n  var day = date & 0x1f; // 1-31\n\n  var month = (date >> 5 & 0xf) - 1; // 1-12, 0-11\n\n  var year = (date >> 9 & 0x7f) + 1980; // 0-128, 1980-2108\n\n  var millisecond = 0;\n  var second = (time & 0x1f) * 2; // 0-29, 0-58 (even numbers)\n\n  var minute = time >> 5 & 0x3f; // 0-59\n\n  var hour = time >> 11 & 0x1f; // 0-23\n\n  return new Date(year, month, day, hour, minute, second, millisecond);\n}\n\nfunction validateFileName(fileName) {\n  if (fileName.indexOf(\"\\\\\") !== -1) {\n    return \"invalid characters in fileName: \" + fileName;\n  }\n\n  if (/^[a-zA-Z]:/.test(fileName) || /^\\//.test(fileName)) {\n    return \"absolute path: \" + fileName;\n  }\n\n  if (fileName.split(\"/\").indexOf(\"..\") !== -1) {\n    return \"invalid relative path: \" + fileName;\n  } // all good\n\n\n  return null;\n}\n\nfunction readAndAssertNoEof(reader, buffer, offset, length, position, callback) {\n  if (length === 0) {\n    // fs.read will throw an out-of-bounds error if you try to read 0 bytes from a 0 byte file\n    return setImmediate(function () {\n      callback(null, newBuffer(0));\n    });\n  }\n\n  reader.read(buffer, offset, length, position, function (err, bytesRead) {\n    if (err) return callback(err);\n\n    if (bytesRead < length) {\n      return callback(new Error(\"unexpected EOF\"));\n    }\n\n    callback();\n  });\n}\n\nutil.inherits(AssertByteCountStream, Transform);\n\nfunction AssertByteCountStream(byteCount) {\n  Transform.call(this);\n  this.actualByteCount = 0;\n  this.expectedByteCount = byteCount;\n}\n\nAssertByteCountStream.prototype._transform = function (chunk, encoding, cb) {\n  this.actualByteCount += chunk.length;\n\n  if (this.actualByteCount > this.expectedByteCount) {\n    var msg = \"too many bytes in the stream. expected \" + this.expectedByteCount + \". got at least \" + this.actualByteCount;\n    return cb(new Error(msg));\n  }\n\n  cb(null, chunk);\n};\n\nAssertByteCountStream.prototype._flush = function (cb) {\n  if (this.actualByteCount < this.expectedByteCount) {\n    var msg = \"not enough bytes in the stream. expected \" + this.expectedByteCount + \". got only \" + this.actualByteCount;\n    return cb(new Error(msg));\n  }\n\n  cb();\n};\n\nutil.inherits(RandomAccessReader, EventEmitter);\n\nfunction RandomAccessReader() {\n  EventEmitter.call(this);\n  this.refCount = 0;\n}\n\nRandomAccessReader.prototype.ref = function () {\n  this.refCount += 1;\n};\n\nRandomAccessReader.prototype.unref = function () {\n  var self = this;\n  self.refCount -= 1;\n  if (self.refCount > 0) return;\n  if (self.refCount < 0) throw new Error(\"invalid unref\");\n  self.close(onCloseDone);\n\n  function onCloseDone(err) {\n    if (err) return self.emit('error', err);\n    self.emit('close');\n  }\n};\n\nRandomAccessReader.prototype.createReadStream = function (options) {\n  var start = options.start;\n  var end = options.end;\n\n  if (start === end) {\n    var emptyStream = new PassThrough();\n    setImmediate(function () {\n      emptyStream.end();\n    });\n    return emptyStream;\n  }\n\n  var stream = this._readStreamForRange(start, end);\n\n  var destroyed = false;\n  var refUnrefFilter = new RefUnrefFilter(this);\n  stream.on(\"error\", function (err) {\n    setImmediate(function () {\n      if (!destroyed) refUnrefFilter.emit(\"error\", err);\n    });\n  });\n\n  refUnrefFilter.destroy = function () {\n    stream.unpipe(refUnrefFilter);\n    refUnrefFilter.unref();\n    stream.destroy();\n  };\n\n  var byteCounter = new AssertByteCountStream(end - start);\n  refUnrefFilter.on(\"error\", function (err) {\n    setImmediate(function () {\n      if (!destroyed) byteCounter.emit(\"error\", err);\n    });\n  });\n\n  byteCounter.destroy = function () {\n    destroyed = true;\n    refUnrefFilter.unpipe(byteCounter);\n    refUnrefFilter.destroy();\n  };\n\n  return stream.pipe(refUnrefFilter).pipe(byteCounter);\n};\n\nRandomAccessReader.prototype._readStreamForRange = function (start, end) {\n  throw new Error(\"not implemented\");\n};\n\nRandomAccessReader.prototype.read = function (buffer, offset, length, position, callback) {\n  var readStream = this.createReadStream({\n    start: position,\n    end: position + length\n  });\n  var writeStream = new Writable();\n  var written = 0;\n\n  writeStream._write = function (chunk, encoding, cb) {\n    chunk.copy(buffer, offset + written, 0, chunk.length);\n    written += chunk.length;\n    cb();\n  };\n\n  writeStream.on(\"finish\", callback);\n  readStream.on(\"error\", function (error) {\n    callback(error);\n  });\n  readStream.pipe(writeStream);\n};\n\nRandomAccessReader.prototype.close = function (callback) {\n  setImmediate(callback);\n};\n\nutil.inherits(RefUnrefFilter, PassThrough);\n\nfunction RefUnrefFilter(context) {\n  PassThrough.call(this);\n  this.context = context;\n  this.context.ref();\n  this.unreffedYet = false;\n}\n\nRefUnrefFilter.prototype._flush = function (cb) {\n  this.unref();\n  cb();\n};\n\nRefUnrefFilter.prototype.unref = function (cb) {\n  if (this.unreffedYet) return;\n  this.unreffedYet = true;\n  this.context.unref();\n};\n\nvar cp437 = \"\\0\\u263A\\u263B\\u2665\\u2666\\u2663\\u2660\\u2022\\u25D8\\u25CB\\u25D9\\u2642\\u2640\\u266A\\u266B\\u263C\\u25BA\\u25C4\\u2195\\u203C\\xB6\\xA7\\u25AC\\u21A8\\u2191\\u2193\\u2192\\u2190\\u221F\\u2194\\u25B2\\u25BC !\\\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~\\u2302\\xC7\\xFC\\xE9\\xE2\\xE4\\xE0\\xE5\\xE7\\xEA\\xEB\\xE8\\xEF\\xEE\\xEC\\xC4\\xC5\\xC9\\xE6\\xC6\\xF4\\xF6\\xF2\\xFB\\xF9\\xFF\\xD6\\xDC\\xA2\\xA3\\xA5\\u20A7\\u0192\\xE1\\xED\\xF3\\xFA\\xF1\\xD1\\xAA\\xBA\\xBF\\u2310\\xAC\\xBD\\xBC\\xA1\\xAB\\xBB\\u2591\\u2592\\u2593\\u2502\\u2524\\u2561\\u2562\\u2556\\u2555\\u2563\\u2551\\u2557\\u255D\\u255C\\u255B\\u2510\\u2514\\u2534\\u252C\\u251C\\u2500\\u253C\\u255E\\u255F\\u255A\\u2554\\u2569\\u2566\\u2560\\u2550\\u256C\\u2567\\u2568\\u2564\\u2565\\u2559\\u2558\\u2552\\u2553\\u256B\\u256A\\u2518\\u250C\\u2588\\u2584\\u258C\\u2590\\u2580\\u03B1\\xDF\\u0393\\u03C0\\u03A3\\u03C3\\xB5\\u03C4\\u03A6\\u0398\\u03A9\\u03B4\\u221E\\u03C6\\u03B5\\u2229\\u2261\\xB1\\u2265\\u2264\\u2320\\u2321\\xF7\\u2248\\xB0\\u2219\\xB7\\u221A\\u207F\\xB2\\u25A0\\xA0\";\n\nfunction decodeBuffer(buffer, start, end, isUtf8) {\n  if (isUtf8) {\n    return buffer.toString(\"utf8\", start, end);\n  } else {\n    var result = \"\";\n\n    for (var i = start; i < end; i++) {\n      result += cp437[buffer[i]];\n    }\n\n    return result;\n  }\n}\n\nfunction readUInt64LE(buffer, offset) {\n  // there is no native function for this, because we can't actually store 64-bit integers precisely.\n  // after 53 bits, JavaScript's Number type (IEEE 754 double) can't store individual integers anymore.\n  // but since 53 bits is a whole lot more than 32 bits, we do our best anyway.\n  var lower32 = buffer.readUInt32LE(offset);\n  var upper32 = buffer.readUInt32LE(offset + 4); // we can't use bitshifting here, because JavaScript bitshifting only works on 32-bit integers.\n\n  return upper32 * 0x100000000 + lower32; // as long as we're bounds checking the result of this function against the total file size,\n  // we'll catch any overflow errors, because we already made sure the total file size was within reason.\n} // Node 10 deprecated new Buffer().\n\n\nvar newBuffer;\n\nif (typeof Buffer.allocUnsafe === \"function\") {\n  newBuffer = function newBuffer(len) {\n    return Buffer.allocUnsafe(len);\n  };\n} else {\n  newBuffer = function newBuffer(len) {\n    return new Buffer(len);\n  };\n}\n\nfunction defaultCallback(err) {\n  if (err) throw err;\n}","map":null,"metadata":{},"sourceType":"script"}